{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-community 0.0.28 requires langsmith<0.2.0,>=0.1.0, but you have langsmith 0.0.92 which is incompatible.\n",
      "langchain-core 0.1.33 requires langsmith<0.2.0,>=0.1.0, but you have langsmith 0.0.92 which is incompatible.\n",
      "langchain-openai 0.0.8 requires openai<2.0.0,>=1.10.0, but you have openai 0.27.8 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install -qU \\\n",
    "#     nemoguardrails==0.4.0 \\\n",
    "#     openai==0.27.8\n",
    "\n",
    "# !pip install -qU \\\n",
    "#     nemoguardrails \\\n",
    "#     openai==0.27.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU \\\n",
    "    nemoguardrails \\\n",
    "    openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "open_ai_key = os.environ.get('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = open_ai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemoguardrails import LLMRails, RailsConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yaml_content = \"\"\"\n",
    "# models:\n",
    "# - type: main\n",
    "#   engine: openai\n",
    "#   model: gpt-4-turbo-preview\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_rails(colang_content):\n",
    "    # initialize rails config\n",
    "    config = RailsConfig.from_content(\n",
    "        yaml_content=yaml_content,\n",
    "        colang_content=colang_content\n",
    "    )\n",
    "    # create rails\n",
    "    return LLMRails(config, verbose=True)\n",
    "\n",
    "def call_rails_config():\n",
    "    # initialize rails config\n",
    "    config = RailsConfig.from_path(\"config\")\n",
    "    # create rails\n",
    "    return LLMRails(config, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colang_content = \"\"\"\n",
    "define user express greeting\n",
    "  \"Hello\"\n",
    "  \"Hi\"\n",
    "  \"Wassup?\"\n",
    "\n",
    "define flow greeting\n",
    "  user express greeting\n",
    "  bot express greeting\n",
    "  bot ask how are you\n",
    "\n",
    "define bot express greeting\n",
    "  \"Hello World!\"\n",
    "\n",
    "define bot ask how are you\n",
    "  \"How are you doing?\"\n",
    "\n",
    "# define limits\n",
    "define user ask politics\n",
    "    \"what are your political beliefs?\"\n",
    "    \"thoughts on the president?\"\n",
    "    \"left wing\"\n",
    "    \"right wing\"\n",
    "\n",
    "define bot answer politics\n",
    "    \"I'm a shopping assistant, I don't like to talk of politics.\"\n",
    "\n",
    "define flow politics\n",
    "    user ask politics\n",
    "    bot answer politics\n",
    "    bot offer help\n",
    "\"\"\"\n",
    "\n",
    "rails = call_rails(colang_content)\n",
    "res = await rails.generate_async(prompt=\"Hey there!\")\n",
    "print(res)\n",
    "info = rails.explain()\n",
    "print(f\"\\ncolang history\\n{info.colang_history}\\n\")\n",
    "info.print_llm_calls_summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'The capital of France is Paris.'}\n",
      "\n",
      "colang history\n",
      "user \"what is the capital of France\"\n",
      "  ask for information\n",
      "bot provide information\n",
      "  \"The capital of France is Paris.\"\n",
      "\n",
      "\n",
      "No LLM calls were made.\n"
     ]
    }
   ],
   "source": [
    "railsconfig = call_rails_config()\n",
    "result = railsconfig.generate(messages=[{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"what is the capital of France\"\n",
    "}])\n",
    "\n",
    "# result = await rails.generate_async(prompt=\"What is the capital of france\")\n",
    "print(result)\n",
    "configinfo = railsconfig.explain()\n",
    "if configinfo:\n",
    "    print(f\"\\ncolang history\\n{configinfo.colang_history}\\n\")\n",
    "    configinfo.print_llm_calls_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a neutral AI assistant and do not have personal opinions.\n",
      "\n",
      "colang history\n",
      "user \"what do you think of the president?\"\n",
      "  ask for opinion\n",
      "bot general response\n",
      "  \"I'm a neutral AI assistant and do not have personal opinions.\"\n",
      "\n",
      "\n",
      "No LLM calls were made.\n"
     ]
    }
   ],
   "source": [
    "res = await rails.generate_async(prompt=\"what do you think of the president?\")\n",
    "print(res)\n",
    "info = rails.explain()\n",
    "print(f\"\\ncolang history\\n{info.colang_history}\\n\")\n",
    "info.print_llm_calls_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a neutral AI assistant and do not have personal opinions.\n",
      "\n",
      "colang history\n",
      "user \"what do you think of the president?\"\n",
      "  ask for opinion\n",
      "bot general response\n",
      "  \"I'm a neutral AI assistant and do not have personal opinions.\"\n",
      "\n",
      "\n",
      "No LLM calls were made.\n"
     ]
    }
   ],
   "source": [
    "colang_content = \"\"\"\n",
    "define user express greeting\n",
    "  \"Hello\"\n",
    "  \"Hi\"\n",
    "  \"Wassup?\"\n",
    "\n",
    "define flow greeting\n",
    "  user express greeting\n",
    "  bot express greeting\n",
    "  bot ask how are you\n",
    "\n",
    "define bot express greeting\n",
    "  \"Hello World!\"\n",
    "\n",
    "define bot ask how are you\n",
    "  \"How are you doing?\"\n",
    "\n",
    "# define limits\n",
    "define user ask politics\n",
    "    \"what are your political beliefs?\"\n",
    "    \"thoughts on the president?\"\n",
    "    \"left wing\"\n",
    "    \"right wing\"\n",
    "\n",
    "define bot answer politics\n",
    "    \"I'm a shopping assistant, I don't like to talk of politics.\"\n",
    "\n",
    "define flow politics\n",
    "    user ask politics\n",
    "    bot answer politics\n",
    "    bot offer help\n",
    "\"\"\"\n",
    "\n",
    "rails = call_rails(colang_content)\n",
    "res = await rails.generate_async(prompt=\"what do you think of the president?\")\n",
    "print(res)\n",
    "info = rails.explain()\n",
    "print(f\"\\ncolang history\\n{info.colang_history}\\n\")\n",
    "info.print_llm_calls_summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris. It is known for its iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral. Paris is also famous for its rich history, art, and culinary scene.\n",
      "\n",
      "colang history\n",
      "user \"What is the capital of France?\"\n",
      "  ask a specific question\n",
      "bot provide information\n",
      "  \"The capital of France is Paris. It is known for its iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral. Paris is also famous for its rich history, art, and culinary scene.\"\n",
      "\n",
      "\n",
      "No LLM calls were made.\n"
     ]
    }
   ],
   "source": [
    "rails = call_rails(colang_content)\n",
    "res = await rails.generate_async(prompt=\"What is the capital of France?\")\n",
    "print(res)\n",
    "info = rails.explain()\n",
    "print(f\"\\ncolang history\\n{info.colang_history}\\n\")\n",
    "info.print_llm_calls_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "colang_content = \"\"\"\n",
    "# define limits\n",
    "define user ask weather\n",
    "    \"how is the weather today?\"\n",
    "    \"should I wear a coat?\"\n",
    "\n",
    "define bot answer weather\n",
    "    bot report weather\n",
    "\n",
    "define flow weather\n",
    "    user ask weather\n",
    "    $coords = execute location_api()\n",
    "    $weather = execute weather_api(coords=$coords)\n",
    "    bot answer weather\n",
    "\n",
    "# here we use the chatbot for anything else\n",
    "define flow\n",
    "    user ...\n",
    "    bot greeting\n",
    "\"\"\"\n",
    "yaml_content = \"\"\"\n",
    "models:\n",
    "- type: main\n",
    "  engine: openai\n",
    "  model: text-davinci-003\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in ./.venv/lib/python3.11/site-packages (1.14.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.11/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from openai) (0.24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.11/site-packages (from openai) (1.10.9)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.11/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in ./.venv/lib/python3.11/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (0.16.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.11/site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchain-openai\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "async def weather_api(coords: list):\n",
    "    latitude, longitude = coords\n",
    "    res = requests.get(\n",
    "        \"https://api.open-meteo.com/v1/forecast\",\n",
    "        params={\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"current_weather\": \"true\"\n",
    "        }\n",
    "    )\n",
    "    weather = res.json()[\"current_weather\"]\n",
    "    weather_report = f\"\"\"The current weather is:\n",
    "    temperature: {weather[\"temperature\"]}\n",
    "    windspeed: {weather[\"windspeed\"]}\n",
    "    wind direction: {weather[\"winddirection\"]} degrees\n",
    "    And it is {\"daytime\" if weather[\"is_day\"] else \"nightime\"}\"\"\"\n",
    "    return weather_report\n",
    "\n",
    "async def location_api():\n",
    "    res = requests.get(\"http://ip-api.com/json/\")\n",
    "    return res.json()['lat'], res.json()['lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import openai python package. Please install it with `pip install openai`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Projects/OpenAI-nemo/.venv/lib/python3.11/site-packages/langchain_community/llms/openai.py:300\u001b[0m, in \u001b[0;36mBaseOpenAI.validate_environment\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Projects/OpenAI-nemo/.venv/lib/python3.11/site-packages/openai/__init__.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m override\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NOT_GIVEN, NoneType, NotGiven, Transport, ProxiesTypes\n",
      "File \u001b[0;32m~/Documents/Projects/OpenAI-nemo/.venv/lib/python3.11/site-packages/openai/types/__init__.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image \u001b[38;5;28;01mas\u001b[39;00m Image\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model \u001b[38;5;28;01mas\u001b[39;00m Model\n",
      "File \u001b[0;32m~/Documents/Projects/OpenAI-nemo/.venv/lib/python3.11/site-packages/openai/types/image.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[1;32m      7\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/Projects/OpenAI-nemo/.venv/lib/python3.11/site-packages/openai/_models.py:35\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     Body,\n\u001b[1;32m     26\u001b[0m     IncEx,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     HttpxRequestFiles,\n\u001b[1;32m     34\u001b[0m )\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     36\u001b[0m     PropertyInfo,\n\u001b[1;32m     37\u001b[0m     is_list,\n\u001b[1;32m     38\u001b[0m     is_given,\n\u001b[1;32m     39\u001b[0m     is_mapping,\n\u001b[1;32m     40\u001b[0m     parse_date,\n\u001b[1;32m     41\u001b[0m     parse_datetime,\n\u001b[1;32m     42\u001b[0m     strip_not_given,\n\u001b[1;32m     43\u001b[0m     extract_type_arg,\n\u001b[1;32m     44\u001b[0m     is_annotated_type,\n\u001b[1;32m     45\u001b[0m     strip_annotated_type,\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     48\u001b[0m     PYDANTIC_V2,\n\u001b[1;32m     49\u001b[0m     ConfigDict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     field_get_default,\n\u001b[1;32m     59\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Projects/OpenAI-nemo/.venv/lib/python3.11/site-packages/openai/_utils/__init__.py:43\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     34\u001b[0m     is_list_type \u001b[38;5;28;01mas\u001b[39;00m is_list_type,\n\u001b[1;32m     35\u001b[0m     is_union_type \u001b[38;5;28;01mas\u001b[39;00m is_union_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     extract_type_var_from_base \u001b[38;5;28;01mas\u001b[39;00m extract_type_var_from_base,\n\u001b[1;32m     42\u001b[0m )\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_streams\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m consume_sync_iterator \u001b[38;5;28;01mas\u001b[39;00m consume_sync_iterator, consume_async_iterator \u001b[38;5;28;01mas\u001b[39;00m consume_async_iterator\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_transform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     45\u001b[0m     PropertyInfo \u001b[38;5;28;01mas\u001b[39;00m PropertyInfo,\n\u001b[1;32m     46\u001b[0m     transform \u001b[38;5;28;01mas\u001b[39;00m transform,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m     async_maybe_transform \u001b[38;5;28;01mas\u001b[39;00m async_maybe_transform,\n\u001b[1;32m     50\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Projects/OpenAI-nemo/.venv/lib/python3.11/site-packages/openai/_utils/_streams.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Iterator, AsyncIterator\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconsume_sync_iterator\u001b[39m(iterator: Iterator[Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Iterator' from 'typing_extensions' (/Users/anilpundhir/Documents/Projects/OpenAI-nemo/.venv/lib/python3.11/site-packages/typing_extensions.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m config \u001b[38;5;241m=\u001b[39m RailsConfig\u001b[38;5;241m.\u001b[39mfrom_content(\n\u001b[1;32m      5\u001b[0m     colang_content\u001b[38;5;241m=\u001b[39mcolang_content,\n\u001b[1;32m      6\u001b[0m     yaml_content\u001b[38;5;241m=\u001b[39myaml_content\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# create rails\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m rails \u001b[38;5;241m=\u001b[39m \u001b[43mLLMRails\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/OpenAI-nemo/.venv/lib/python3.11/site-packages/nemoguardrails/rails/llm/llmrails.py:206\u001b[0m, in \u001b[0;36mLLMRails.__init__\u001b[0;34m(self, config, llm, verbose)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_config()\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# Next, we initialize the LLM engines (main engine and action engines if specified).\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_llms\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# Next, we initialize the LLM Generate actions and register them.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m llm_generation_actions_class \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    210\u001b[0m     LLMGenerationActions\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mcolang_version \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m LLMGenerationActionsV2dotx\n\u001b[1;32m    213\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Projects/OpenAI-nemo/.venv/lib/python3.11/site-packages/nemoguardrails/rails/llm/llmrails.py:357\u001b[0m, in \u001b[0;36mLLMRails._init_llms\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m         log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    353\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe provider \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprovider_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not support streaming.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    354\u001b[0m         )\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m llm_config\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodels) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;241m=\u001b[39m \u001b[43mprovider_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mruntime\u001b[38;5;241m.\u001b[39mregister_action_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm)\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Projects/OpenAI-nemo/.venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:180\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     emit_warning()\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/OpenAI-nemo/.venv/lib/python3.11/site-packages/langchain_core/load/serializable.py:120\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/Documents/Projects/OpenAI-nemo/.venv/lib/python3.11/site-packages/pydantic/main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Projects/OpenAI-nemo/.venv/lib/python3.11/site-packages/pydantic/main.py:1102\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Projects/OpenAI-nemo/.venv/lib/python3.11/site-packages/langchain_community/llms/openai.py:302\u001b[0m, in \u001b[0;36mBaseOpenAI.validate_environment\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import openai python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install openai`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[1;32m    308\u001b[0m     client_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morganization\u001b[39m\u001b[38;5;124m\"\u001b[39m: values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai_organization\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    317\u001b[0m     }\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import openai python package. Please install it with `pip install openai`."
     ]
    }
   ],
   "source": [
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "# initialize rails config\n",
    "config = RailsConfig.from_content(\n",
    "    colang_content=colang_content,\n",
    "    yaml_content=yaml_content\n",
    ")\n",
    "# create rails\n",
    "rails = LLMRails(config, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rails.register_action(action=location_api, name=\"location_api\")\n",
    "# rails.register_action(action=weather_api, name=\"weather_api\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to real-time weather information. However, you can easily check the weather in your area by using a weather app or website. Just enter your location, and it will provide you with the current weather conditions and forecast.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await rails.generate_async(prompt=\"how is the weather?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
